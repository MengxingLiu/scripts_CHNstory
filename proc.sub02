#!/bin/tcsh -xef

echo "auto-generated by afni_proc.py, Wed Jul 24 16:24:50 2019"
echo "(version 6.30, June 3, 2019)"
echo "execution started: `date`"

# to execute via tcsh: 
#   tcsh -xef proc.sub02 |& tee output.proc.sub02
# to execute via bash: 
#   tcsh -xef proc.sub02 2>&1 | tee output.proc.sub02

# =========================== auto block: setup ============================
# script setup

# take note of the AFNI version
afni -ver

# check that the current AFNI version is recent enough
afni_history -check_date 10 May 2019
if ( $status ) then
    echo "** this script requires newer AFNI binaries (than 10 May 2019)"
    echo "   (consider: @update.afni.binaries -defaults)"
    exit
endif

# the user may specify a single subject to run with
if ( $#argv > 0 ) then
    set subj = $argv[1]
else
    set subj = sub02
endif

# assign output directory name
set output_dir = $subj.results

# verify that the results directory does not yet exist
if ( -d $output_dir ) then
    echo output dir "$subj.results" already exists
    exit
endif

# set list of runs
set runs = (`count -digits 2 1 5`)

# create results and stimuli directories
mkdir $output_dir
mkdir $output_dir/stimuli

# copy stim files into stimulus directory
cp                                                                                              \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_CS.01.1D  \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_nNS.01.1D \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_SW.01.1D  \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_US.01.1D  \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_aNS.01.1D \
    $output_dir/stimuli

# copy anatomy to results dir
3dcopy                                                                                 \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/"$subj"/orig_files/Anatomical+orig \
    $output_dir/Anatomical

# ============================ auto block: tcat ============================
# apply 3dTcat to copy input dsets to results dir,
# while removing the first 6 TRs
3dTcat -prefix $output_dir/pb00.$subj.r01.tcat \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/"$subj"/orig_files/run01+orig'[6..184]'
3dTcat -prefix $output_dir/pb00.$subj.r02.tcat \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/"$subj"/orig_files/run02+orig'[6..174]'
3dTcat -prefix $output_dir/pb00.$subj.r03.tcat \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/"$subj"/orig_files/run03+orig'[6..177]'
3dTcat -prefix $output_dir/pb00.$subj.r04.tcat \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/"$subj"/orig_files/run04+orig'[6..192]'
3dTcat -prefix $output_dir/pb00.$subj.r05.tcat \
    /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/"$subj"/orig_files/run05+orig'[6..186]'

# and make note of repetitions (TRs) per run
set tr_counts = ( 179 169 172 187 181 )

# -------------------------------------------------------
# enter the results directory (can begin processing data)
cd $output_dir


# ========================== auto block: outcount ==========================
# data check: compute outlier fraction for each volume
touch out.pre_ss_warn.txt
foreach run ( $runs )
    3dToutcount -automask -fraction -polort 3 -legendre                     \
                pb00.$subj.r$run.tcat+orig > outcount.r$run.1D

    # outliers at TR 0 might suggest pre-steady state TRs
    if ( `1deval -a outcount.r$run.1D"{0}" -expr "step(a-0.4)"` ) then
        echo "** TR #0 outliers: possible pre-steady state TRs in run $run" \
            >> out.pre_ss_warn.txt
    endif
end

# catenate outlier counts into a single time series
cat outcount.r*.1D > outcount_rall.1D

# ================================ despike =================================
# apply 3dDespike to each run
foreach run ( $runs )
    3dDespike -NEW -nomask -prefix pb01.$subj.r$run.despike \
        pb00.$subj.r$run.tcat+orig
end

# ================================= tshift =================================
# time shift data so all slice timing is the same 
foreach run ( $runs )
    3dTshift -tzero 0 -quintic -prefix pb02.$subj.r$run.tshift \
             pb01.$subj.r$run.despike+orig
end

# --------------------------------
# extract volreg registration base
3dbucket -prefix vr_base pb02.$subj.r01.tshift+orig"[2]"

# ================================= align ==================================
# for e2a: compute anat alignment transformation to EPI registration base
# (new anat will be intermediate, stripped, Anatomical_ns+orig)
align_epi_anat.py -anat2epi -anat Anatomical+orig \
       -save_skullstrip -suffix _al_junk          \
       -epi vr_base+orig -epi_base 0              \
       -epi_strip 3dAutomask                      \
       -cost lpc+ZZ                               \
       -volreg off -tshift off

# ================================== tlrc ==================================
# warp anatomy to standard space
@auto_tlrc -base MNI152_T1_2009c+tlrc -input Anatomical_ns+orig -no_ss

# store forward transformation matrix in a text file
cat_matvec Anatomical_ns+tlrc::WARP_DATA -I > warp.anat.Xat.1D

# ================================= volreg =================================
# align each dset to base volume, to anat, warp to tlrc space

# verify that we have a +tlrc warp dataset
if ( ! -f Anatomical_ns+tlrc.HEAD ) then
    echo "** missing +tlrc warp dataset: Anatomical_ns+tlrc.HEAD" 
    exit
endif

# register and warp
foreach run ( $runs )
    # register each volume to the base image
    3dvolreg -verbose -zpad 1 -base vr_base+orig                \
             -1Dfile dfile.r$run.1D -prefix rm.epi.volreg.r$run \
             -cubic                                             \
             -1Dmatrix_save mat.r$run.vr.aff12.1D               \
             pb02.$subj.r$run.tshift+orig

    # create an all-1 dataset to mask the extents of the warp
    3dcalc -overwrite -a pb02.$subj.r$run.tshift+orig -expr 1   \
           -prefix rm.epi.all1

    # catenate volreg/epi2anat/tlrc xforms
    cat_matvec -ONELINE                                         \
               Anatomical_ns+tlrc::WARP_DATA -I                 \
               Anatomical_al_junk_mat.aff12.1D -I               \
               mat.r$run.vr.aff12.1D > mat.r$run.warp.aff12.1D

    # apply catenated xform: volreg/epi2anat/tlrc
    3dAllineate -base Anatomical_ns+tlrc                        \
                -input pb02.$subj.r$run.tshift+orig             \
                -1Dmatrix_apply mat.r$run.warp.aff12.1D         \
                -mast_dxyz 3                                    \
                -prefix rm.epi.nomask.r$run

    # warp the all-1 dataset for extents masking 
    3dAllineate -base Anatomical_ns+tlrc                        \
                -input rm.epi.all1+orig                         \
                -1Dmatrix_apply mat.r$run.warp.aff12.1D         \
                -mast_dxyz 3 -final NN -quiet                   \
                -prefix rm.epi.1.r$run

    # make an extents intersection mask of this run
    3dTstat -min -prefix rm.epi.min.r$run rm.epi.1.r$run+tlrc
end

# make a single file of registration params
cat dfile.r*.1D > dfile_rall.1D

# ----------------------------------------
# create the extents mask: mask_epi_extents+tlrc
# (this is a mask of voxels that have valid data at every TR)
3dMean -datum short -prefix rm.epi.mean rm.epi.min.r*.HEAD 
3dcalc -a rm.epi.mean+tlrc -expr 'step(a-0.999)' -prefix mask_epi_extents

# and apply the extents mask to the EPI data 
# (delete any time series with missing data)
foreach run ( $runs )
    3dcalc -a rm.epi.nomask.r$run+tlrc -b mask_epi_extents+tlrc \
           -expr 'a*b' -prefix pb03.$subj.r$run.volreg
end

# warp the volreg base EPI dataset to make a final version
cat_matvec -ONELINE                                             \
           Anatomical_ns+tlrc::WARP_DATA -I                     \
           Anatomical_al_junk_mat.aff12.1D -I  > mat.basewarp.aff12.1D

3dAllineate -base Anatomical_ns+tlrc                            \
            -input vr_base+orig                                 \
            -1Dmatrix_apply mat.basewarp.aff12.1D               \
            -mast_dxyz 3                                        \
            -prefix final_epi_vr_base

# create an anat_final dataset, aligned with stats
3dcopy Anatomical_ns+tlrc anat_final.$subj

# record final registration costs
3dAllineate -base final_epi_vr_base+tlrc -allcostX              \
            -input anat_final.$subj+tlrc |& tee out.allcostX.txt

# -----------------------------------------
# warp anat follower datasets (affine)
3dAllineate -source Anatomical+orig                             \
            -master anat_final.$subj+tlrc                       \
            -final wsinc5 -1Dmatrix_apply warp.anat.Xat.1D      \
            -prefix anat_w_skull_warped

# ================================== blur ==================================
# blur each volume of each run
foreach run ( $runs )
    3dmerge -1blur_fwhm 6.0 -doall -prefix pb04.$subj.r$run.blur \
            pb03.$subj.r$run.volreg+tlrc
end

# ================================= scale ==================================
# scale each voxel time series to have a mean of 100
# (be sure no negatives creep in)
# (subject to a range of [0,200])
foreach run ( $runs )
    3dTstat -prefix rm.mean_r$run pb04.$subj.r$run.blur+tlrc
    3dcalc -a pb04.$subj.r$run.blur+tlrc -b rm.mean_r$run+tlrc \
           -c mask_epi_extents+tlrc                            \
           -expr 'c * min(200, a/b*100)*step(a)*step(b)'       \
           -prefix pb05.$subj.r$run.scale
end

# ================================ regress =================================

# compute de-meaned motion parameters (for use in regression)
1d_tool.py -infile dfile_rall.1D -set_run_lengths 179 169 172 187 181\
           -demean -write motion_demean.1D

# compute motion parameter derivatives (just to have)
1d_tool.py -infile dfile_rall.1D -set_run_lengths 179 169 172 187 181 \
           -derivative -demean -write motion_deriv.1D

# create censor file motion_${subj}_censor.1D, for censoring motion 
1d_tool.py -infile dfile_rall.1D -set_run_lengths 179 169 172 187 181 \
    -show_censor_count -censor_prev_TR                                \
    -censor_motion 0.3 motion_${subj}

# note TRs that were not censored
set ktrs = `1d_tool.py -infile motion_${subj}_censor.1D               \
                       -show_trs_uncensored encoded`

# ------------------------------
# run the regression analysis
3dDeconvolve -input pb05.$subj.r*.scale+tlrc.HEAD                     \
    -censor motion_${subj}_censor.1D                                  \
    -ortvec motion_demean.1D mot_demean                               \
    -polort 3                                                         \
    -num_stimts 5                                                     \
    -stim_times_AM1 1 stimuli/stim_times_CS.01.1D 'dmBLOCK'           \
    -stim_label 1 CS                                                  \
    -stim_times_AM1 2 stimuli/stim_times_nNS.01.1D 'dmBLOCK'          \
    -stim_label 2 nNS                                                 \
    -stim_times_AM1 3 stimuli/stim_times_SW.01.1D 'dmBLOCK'           \
    -stim_label 3 SW                                                  \
    -stim_times_AM1 4 stimuli/stim_times_US.01.1D 'dmBLOCK'           \
    -stim_label 4 US                                                  \
    -stim_times_AM1 5 stimuli/stim_times_aNS.01.1D 'dmBLOCK'          \
    -stim_label 5 aNS                                                 \
    -gltsym 'SYM: nNS -CS'                                            \
    -glt_label 1 nNS-CS                                               \
    -gltsym 'SYM: CS -US'                                             \
    -glt_label 2 CS-US                                                \
    -gltsym 'SYM: US -SW'                                             \
    -glt_label 3 US-SW                                                \
    -gltsym 'SYM: nNS -aNS'                                           \
    -glt_label 4 nNS-aNS                                              \
    -jobs 6                                                           \
    -fout -tout -x1D X.xmat.1D -xjpeg X.jpg                           \
    -x1D_uncensored X.nocensor.xmat.1D                                \
    -fitts fitts.$subj                                                \
    -errts errts.${subj}                                              \
    -bucket stats.$subj


# if 3dDeconvolve fails, terminate the script
if ( $status != 0 ) then
    echo '---------------------------------------'
    echo '** 3dDeconvolve error, failing...'
    echo '   (consider the file 3dDeconvolve.err)'
    exit
endif


# display any large pairwise correlations from the X-matrix
1d_tool.py -show_cormat_warnings -infile X.xmat.1D |& tee out.cormat_warn.txt

# display degrees of freedom info from X-matrix
1d_tool.py -show_df_info -infile X.xmat.1D |& tee out.df_info.txt

# create an all_runs dataset to match the fitts, errts, etc.
3dTcat -prefix all_runs.$subj pb05.$subj.r*.scale+tlrc.HEAD

# --------------------------------------------------
# create a temporal signal to noise ratio dataset 
#    signal: if 'scale' block, mean should be 100
#    noise : compute standard deviation of errts
3dTstat -mean -prefix rm.signal.all all_runs.$subj+tlrc"[$ktrs]"
3dTstat -stdev -prefix rm.noise.all errts.${subj}+tlrc"[$ktrs]"
3dcalc -a rm.signal.all+tlrc                                          \
       -b rm.noise.all+tlrc                                           \
       -expr 'a/b' -prefix TSNR.$subj 

# create ideal files for fixed response stim types
1dcat X.nocensor.xmat.1D'[20]' > ideal_CS.1D
1dcat X.nocensor.xmat.1D'[21]' > ideal_nNS.1D
1dcat X.nocensor.xmat.1D'[22]' > ideal_SW.1D
1dcat X.nocensor.xmat.1D'[23]' > ideal_US.1D
1dcat X.nocensor.xmat.1D'[24]' > ideal_aNS.1D

# --------------------------------------------------------
# compute sum of non-baseline regressors from the X-matrix
# (use 1d_tool.py to get list of regressor colums)
set reg_cols = `1d_tool.py -infile X.nocensor.xmat.1D -show_indices_interest`
3dTstat -sum -prefix sum_ideal.1D X.nocensor.xmat.1D"[$reg_cols]"

# also, create a stimulus-only X-matrix, for easy review
1dcat X.nocensor.xmat.1D"[$reg_cols]" > X.stim.xmat.1D

# ================== auto block: generate review scripts ===================

# generate a review script for the unprocessed EPI data
gen_epi_review.py -script @epi_review.$subj    \
    -dsets pb00.$subj.r*.tcat+orig.HEAD

# generate scripts to review single subject results
# (try with defaults, but do not allow bad exit status)
gen_ss_review_scripts.py -mot_limit 0.3 -exit0 \
    -ss_review_dset out.ss_review.$subj.txt    \
    -write_uvars_json out.ss_review_uvars.json

# ========================== auto block: finalize ==========================

# remove temporary files
\rm -f rm.*

# if the basic subject review script is here, run it
# (want this to be the last text output)
if ( -e @ss_review_basic ) then
    ./@ss_review_basic |& tee out.ss_review.$subj.txt

endif

# remove preprocessing files to save disk space
\rm dfile.r*.1D pb*.$subj.r*.*

# return to parent directory (just in case...)
cd ..

echo "execution finished: `date`"




# ==========================================================================
# script generated by the command:
#
# afni_proc.py -subj_id sub02 -script proc.sub02 -scr_overwrite -blocks                           \
#     despike tshift align tlrc volreg blur scale regress -copy_anat                              \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/sub02/orig_files/Anatomical+orig          \
#     -tlrc_base MNI152_T1_2009c+tlrc -tcat_remove_first_trs 6                                    \
#     -remove_preproc_files -dsets                                                                \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/sub02/orig_files/run01+orig.HEAD          \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/sub02/orig_files/run02+orig.HEAD          \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/sub02/orig_files/run03+orig.HEAD          \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/sub02/orig_files/run04+orig.HEAD          \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/sub02/orig_files/run05+orig.HEAD          \
#     -align_opts_aea -cost lpc+ZZ -volreg_align_to third -volreg_align_e2a                       \
#     -volreg_tlrc_warp -blur_size 6.0 -regress_stim_times                                        \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_CS.01.1D  \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_nNS.01.1D \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_SW.01.1D  \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_US.01.1D  \
#     /bcbl/home/public/Mengxing/CHNstory/story2016fMRI/scripts/Wave_1Dfiles/stim_times_aNS.01.1D \
#     -regress_stim_labels CS nNS SW US aNS -regress_basis dmBLOCK                                \
#     -regress_stim_types AM1 -regress_censor_motion 0.3 -regress_opts_3dD                        \
#     -gltsym 'SYM: nNS -CS' -glt_label 1 nNS-CS -gltsym 'SYM: CS -US'                            \
#     -glt_label 2 CS-US -gltsym 'SYM: US -SW' -glt_label 3 US-SW -gltsys                         \
#     'SYM: nNS -aNS' -glt_label 4 nNS-aNS -jobs 6 -regress_make_ideal_sum                        \
#     sum_ideal.1D
